{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dd1ce5c",
   "metadata": {},
   "source": [
    "### Master of Applied Artificial Intelligence\n",
    "\n",
    "**Course: TC5035 - Proyecto Integrador**\n",
    "\n",
    "<img src=\"https://github.com/Medicenchapin/Proyecto-Integrador/blob/main/assets/logo.png?raw=1\" alt=\"Image Alt Text\" width=\"500\"/>\n",
    "\n",
    "\n",
    "**Feature engineering**\n",
    "\n",
    "Tutor: Dr. Horario Martinez Alfaro\n",
    "\n",
    "\n",
    "Team members:\n",
    "* Ignacio Jose Aguilar Garcia - A00819762\n",
    "* Alejandro Calderon Aguilar - A01795353\n",
    "* Ricardo Mar Cupido - A01795394"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a700fd4",
   "metadata": {},
   "source": [
    "# FE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e145daf5",
   "metadata": {},
   "source": [
    "The model contains an individualized FE:\n",
    "\n",
    "Each row represents a client (or case).\n",
    "\n",
    "Within each row, in the drivers column, you have something like:\n",
    "\n",
    "```bash\n",
    "[\n",
    "  {\"feature\": \"arpu_90_days\", \"value\": 123.4, \"impact\": 0.05},\n",
    "  {\"feature\": \"contacts\", \"value\": 3, \"impact\": -0.03},\n",
    "  {\"feature\": \"plan_postpaid\", \"value\": 1, \"impact\": 0.02},\n",
    "  ...\n",
    "]\n",
    "```\n",
    "\n",
    "That is, each row has its own important features with different weights.\n",
    "ðŸ‘‰ That's why we can't talk about the same set of global top features at the client level,\n",
    "because SHAP tells what was most relevant for that particular prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a27d5fb",
   "metadata": {},
   "source": [
    "## So how do we use this for the prompt?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a2b3ad",
   "metadata": {},
   "source": [
    "We have two possible levels of context in the LLM prompts\n",
    "\n",
    "ðŸ”¹ **Level 1 â€” Global context prompt**\n",
    "\n",
    "\n",
    "Includes an overview of the model and what the features represent:\n",
    "\n",
    "\n",
    "\n",
    "*â€œThe model uses 20 features such as ARPU, previous_calls, plan_postpaid, etc., to predict whether a prepaid user will make a purchase. The following SHAP analysis identifies the most influential features for this user.â€*\n",
    "\n",
    "ðŸ‘‰ This gives the semantic model (Ollama or DeepSeek) the context of what the features are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb950d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def build_global_context(df, feature_playbook=None, top_n=10):\n",
    "    \"\"\"\n",
    "    df: DataFrame final que tiene columna 'drivers', donde cada row tiene\n",
    "        [{\"feature\": str, \"value\": float, \"impact\": float}, ...]\n",
    "    feature_playbook: dict opcional donde describes cada feature con lenguaje humano\n",
    "                      (como el FEATURE_PLAYBOOK que ya tenÃ­as)\n",
    "    \"\"\"\n",
    "    # Expandimos todos los drivers en un solo dataframe\n",
    "    drivers_all = (\n",
    "        df[\"drivers\"]\n",
    "        .explode()\n",
    "        .dropna()\n",
    "        .apply(pd.Series)  # -> columns: feature, value, impact\n",
    "    )\n",
    "\n",
    "    # Importancia global: mean(|impact|)\n",
    "    global_importance = (\n",
    "        drivers_all\n",
    "        .groupby(\"feature\")[\"impact\"]\n",
    "        .apply(lambda s: s.abs().mean())\n",
    "        .sort_values(ascending=False)\n",
    "        .head(top_n)\n",
    "    )\n",
    "\n",
    "    top_features = list(global_importance.index)\n",
    "\n",
    "    # Armamos descripciÃ³n de features\n",
    "    lines = []\n",
    "    for feat in top_features:\n",
    "        if feature_playbook and feat in feature_playbook:\n",
    "            desc = feature_playbook[feat]\n",
    "        else:\n",
    "            desc = \"No description available.\"\n",
    "        lines.append(f\"- {feat}: {desc}\")\n",
    "\n",
    "    features_block = \"\\n\".join(lines)\n",
    "\n",
    "    global_prompt = f\"\"\"\n",
    "    You are helping generate sales guidance for a prepaid telecom campaign.\n",
    "\n",
    "    We have a machine learning model that predicts the probability that a customer will accept an offer (sale = 1).\n",
    "    The model was trained on historical customer behavior and engagement indicators. \n",
    "    Higher score means the customer is more likely to buy if contacted.\n",
    "\n",
    "    The model relies on multiple behavioral and account features. Below are the most influential features overall (averaged across customers), and what they represent:\n",
    "\n",
    "    {features_block}\n",
    "\n",
    "    Rules:\n",
    "    - NEVER reveal internal model weights or math details.\n",
    "    - NEVER invent personal/sensitive attributes not present in the features.\n",
    "    - Keep tone helpful, respectful, and focused on value to customer.\n",
    "    - You are allowed to explain *why the model thinks a segment is likely to buy*, in plain language.\n",
    "        \"\"\".strip()\n",
    "\n",
    "    return global_prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b75cf70",
   "metadata": {},
   "source": [
    "ðŸ”¹ **Level 2 â€” Row-specific prompt (customized by customer)**\n",
    "\n",
    "\n",
    "Here it uses the customer's SHAP drivers (their relevant features, values, and impacts):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897acd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_customer_prompt(row, driver_list, extra_context_cols=None):\n",
    "    \"\"\"\n",
    "    row: una fila de tu df (por ejemplo df.loc[idx])\n",
    "         que tiene columnas humanas tipo 'state_name', 'previous_classification', etc.\n",
    "         y tambiÃ©n 'proba'.\n",
    "\n",
    "    driver_list: lista de dicts tipo:\n",
    "      [\n",
    "        {\"feature\": \"arpu_90_days\", \"value\": 8.24, \"impact\": 0.32},\n",
    "        ...\n",
    "      ]\n",
    "\n",
    "    extra_context_cols: lista de columnas del row que quieres pasar al LLM\n",
    "                        para que hable mÃ¡s personalizado.\n",
    "                        Ej: [\"state_name\", \"previous_classification\", \"arpu_90_days\", \"network_age_years\"]\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Prepara resumen de los drivers SHAP personalizados de este cliente\n",
    "    driver_lines = []\n",
    "    for d in driver_list:\n",
    "        driver_lines.append(\n",
    "            f\"- {d['feature']}: value={d['value']}, impact={d['impact']:+.3f}\"\n",
    "        )\n",
    "    driver_block = \"\\n\".join(driver_lines)\n",
    "\n",
    "    # 2. Agrega contexto humano del cliente (opcional)\n",
    "    context_lines = []\n",
    "    if extra_context_cols:\n",
    "        for col in extra_context_cols:\n",
    "            if col in row:\n",
    "                context_lines.append(f\"{col} = {row[col]}\")\n",
    "    context_block = \"\\n\".join(context_lines) if context_lines else \"No additional context.\"\n",
    "\n",
    "    # 3. Construye el prompt final\n",
    "    prompt = f\"\"\"\n",
    "    We are preparing a telemarketing/sales pitch for a prepaid mobile customer.\n",
    "\n",
    "    Predicted probability of accepting the offer: {row['proba']:.2%}\n",
    "\n",
    "    Relevant context for this customer:\n",
    "    {context_block}\n",
    "\n",
    "    The following factors were most influential in predicting that this customer is likely to accept an offer:\n",
    "    {driver_block}\n",
    "\n",
    "    Task:\n",
    "    1. Explain, in plain language, why this customer might respond positively.\n",
    "    2. Suggest how an agent should position the offer (tone, focus, what to mention).\n",
    "    3. Keep it short and actionable, as guidance for a call center agent.\n",
    "    4. Do NOT mention 'model', 'probability', 'algorithm', 'prediction', or 'SHAP'. Just speak as advice.\n",
    "        \"\"\".strip()\n",
    "\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a842a682",
   "metadata": {},
   "source": [
    "## prompt version 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc89b6e8",
   "metadata": {},
   "source": [
    "```bash\n",
    "    prompt = f\"\"\"\n",
    "    The model predicts a sale probability of {proba:.2%} for this prepaid customer.\n",
    "    The most influential factors for this prediction were:\n",
    "    {summary}\n",
    "\n",
    "    Explain, in natural language, why these features may lead to this prediction.\n",
    "    Provide a concise and interpretable summary.\n",
    "    \"\"\"\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
